---
source_url: https://ai-data-base.com/archives/65208
captured_at: 2026-01-18T13:23:57.531Z
title: "「シリコンの群衆」LLM集団（12体）は人間にどれほど近づくか - AIDB"
category: "unknown"
is_premium: false
publish_date: 2025-03-08T21:08:36+09:00
conversion_method: Readability+Turndown
file_hash: 9bf88363e93274b3
---

人間全体の能力は「群衆の知恵」効果に依存していると考えられています。多様な集団が到達する結論は、一人の専門家の意見よりも常に優るという仮説です。

これまでの研究では、個々のLLMは人間の集合知に及ばないことが示唆されています。LLMおける集合知はどうでしょうか？まだ分かっていません。

そこで研究者らは、12体のLLMを使用し、人間集団の予測と比較する実験を行いました。結果、人間集団と統計的に同等であることが判明したのです。

さらに研究者らは、人間の知恵に触れることでLLMの予測がどう変化するのかも検証しました。

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_65208_thum-1024x576.jpg)

**参照論文情報**

*   タイトル：Wisdom of the Silicon Crowd: LLM Ensemble Prediction Capabilities Match Human Crowd Accuracy
*   機関：ロンドン経済政治大学院, MIT, ペンシルバニア大学
*   著者：Philipp Schoenegger, Indre Tuminauskaite, Peter S. Park, Philip E. Tetlock

**本記事の関連研究**：

*   [GPT-4、Bard、Claude2などの異なるLLMが円卓を囲み議論した結果の回答は品質が高いとの検証報告。円卓ツールも公開](https://ai-data-base.com/archives/55853)
*   [小さなLLMを多数組み合わせることで、単一の巨大モデルに匹敵する可能性](https://ai-data-base.com/archives/64708)
*   [LLMエージェントは同調圧力に弱く考えに固執する傾向があるため、ディベートでバイアスを和らげるのが重要との報告。導入ツールも公開](https://ai-data-base.com/archives/56599)
*   [多様な役割のAIエージェント達に協力してソフトウェアを開発してもらう『ChatDev』登場。論文内容＆使い方を解説](https://ai-data-base.com/archives/54863)

## 背景

LLMの能力を評価する際の主な方法は、特定タスクの固定ベンチマークでのパフォーマンスを測定することです。  
しかしモデルの能力が急速に発達する中、過去に確立された多くのベンチマークは時代遅れとなりつつあります。今求められている理想的なベンチマークは、より難しく、そして網羅的なものです。

一方で、現在の最先端LLMがタスクベンチマークで高い性能を達成しているのは、タスクの表面的な理解によるものかもしれないとの指摘もあります。  
学校のテストで、表面的な暗記で高得点が狙える現象と似ているかもしれません。学生が試験問題の答えを覚えるのと同じように、LLMも、そのトレーニングデータにタスクベンチマークで使用される質問と回答が含まれていれば、暗記して正解できてしまうのです。  
浅い理解と深い理解を区別するのは難しいものの、LLMの推論能力を正確に評価する上では無視できません。トレーニングデータ分布外問題を用意すればいいのですが、LLMの幅広い知識を相手にする場合、設計が難しいといった問題もあります。

そこで今回研究者らは、将来の出来事を予測する独自の問題を使用してLLMと人間の能力を比べるアプローチを取りました。

### 集合知同士で比較するアイデア

これまでの研究では、最先端のモデルと人間集団の予測性能が比較されてきました。例えばGPT-4を単独で評価した実験の結果では、人間の集合知に比べると予測性能が劣っています（すべての質問に対して半分の確率で答えた時のスコアにも及ばなかった事例もあります）。また、ニュース検索と推論システムを組み合わせたLLMシステムにおいても、個々のモデルの予測精度が低いという問題は発生しました（ただし、高度に最適化されたシステムに組み込まれたケースでは人間の精度に匹敵することもありました）。

ここで、人間の場合は集合知で優秀さが測定されているため、LLMの予測精度も集団化することによって向上する可能性があります。そこで研究者らは、シリコン版の「群衆の知恵」効果の有無を検証するため、LLMの群衆を仮想的に作成し、検索システムなどの追加要素を導入せずに、人間の群衆と直接比較することにしました。

### 実験のアプローチ

一つ目の実験では、12のLLMの予測を集約して群衆の予測とします。まず気になるのは、すべての質問に対して半分の確率で答えた時のスコアよりも上回るのかどうかです。  
さらに、LLMの集団が人間の集団を有意に上回るかどうかという、より直接的で発展的な検証も行われました。  
また12のモデル間の予測精度の違いが検証されました。GPT-4、PaLM2、Llama-2-70Bのように、能力やサイズなどが異なるモデル間の差異を検証することで、さらなる洞察が得られるかもしれません。

次に二つ目の実験では、2つの最先端モデルGPT-4とClaude 2（Claude 3も出ましたが、Claude 2の時点で既に高い性能が出ています）が人間の知恵に触れた時にどう反応するのかを見ています。この実験では、初期の予測が新しい証拠で調整され、更新されるかが検証されます。人間の直感的で経験に基づく判断とLLMのデータ処理能力を統合することでシナジーは生まれるのでしょうか？  
次に、人間の予測に触れることでLLMの予測に対する確信度が高まるかどうかを調査されました。  
最後に、LLMの最初の予測と人間がどの程度違うか、そして人間がその予測をどれだけ変更するかが確認されました。

これまでの研究ではAIが人間の判断をどう改善できるかを見てきましたが、今回の論文ではその逆、つまり人間とAIがどのようにうまく協力できるかについて考察されています。以下で詳しく説明します。

プレミアム会員限定コンテンツです

閲覧には、アカウント作成後の決済が必要です。

*   全記事・論文コンテンツを無制限で閲覧可能
*   平日毎日更新、専門家による最新リサーチを配信

[プレミアム会員について](https://ai-data-base.com/premium-visitor)

Copyright © Parks, Inc. All rights reserved.
---
source_url: https://ai-data-base.com/archives/52217
captured_at: 2026-01-18T13:11:58.122Z
title: "大規模言語モデルの毒に用心を データポイズニングのリスク - AIDB"
category: "unknown"
is_premium: false
publish_date: 2025-03-08T21:11:29+09:00
conversion_method: Readability+Turndown
file_hash: 92c1187a0e37b99a
---

私たちの日常生活にAIが浸透する中、その安全性や信頼性についての関心も高まっています。最新の研究によれば、大規模な言語モデルにはまだ見ぬリスクが潜んでいることが明らかになりました。それは「データポイズニング（Data poisoning）」という、AIを訓練するデータを悪用する攻撃手法です。この記事では、そのリスクと対処法について解説します。

![](https://ai-data-base.com/wp-content/uploads/2023/05/AIDB_52217_1-1024x576.jpg)

**目次**[](https://ai-data-base.com/archives/52217#)

*   [ポイズニングって何？](https://ai-data-base.com/archives/52217#%E3%83%9D%E3%82%A4%E3%82%BA%E3%83%8B%E3%83%B3%E3%82%B0%E3%81%A3%E3%81%A6%E4%BD%95%EF%BC%9F)
    *   [AIに毒を飲ませる？](https://ai-data-base.com/archives/52217#AI%E3%81%AB%E6%AF%92%E3%82%92%E9%A3%B2%E3%81%BE%E3%81%9B%E3%82%8B%EF%BC%9F)
    *   [出力に偏りが生み出される](https://ai-data-base.com/archives/52217#%E5%87%BA%E5%8A%9B%E3%81%AB%E5%81%8F%E3%82%8A%E3%81%8C%E7%94%9F%E3%81%BF%E5%87%BA%E3%81%95%E3%82%8C%E3%82%8B)
*   [大規模言語モデルのポイズニング攻撃](https://ai-data-base.com/archives/52217#%E5%A4%A7%E8%A6%8F%E6%A8%A1%E8%A8%80%E8%AA%9E%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AE%E3%83%9D%E3%82%A4%E3%82%BA%E3%83%8B%E3%83%B3%E3%82%B0%E6%94%BB%E6%92%83)
    *   [ダーティーラベルポイズニング](https://ai-data-base.com/archives/52217#%E3%83%80%E3%83%BC%E3%83%86%E3%82%A3%E3%83%BC%E3%83%A9%E3%83%99%E3%83%AB%E3%83%9D%E3%82%A4%E3%82%BA%E3%83%8B%E3%83%B3%E3%82%B0)
    *   [AIの毒見役は誰？](https://ai-data-base.com/archives/52217#AI%E3%81%AE%E6%AF%92%E8%A6%8B%E5%BD%B9%E3%81%AF%E8%AA%B0%EF%BC%9F)
*   [ポイズニング防御策](https://ai-data-base.com/archives/52217#%E3%83%9D%E3%82%A4%E3%82%BA%E3%83%8B%E3%83%B3%E3%82%B0%E9%98%B2%E5%BE%A1%E7%AD%96)
    *   [AIに解毒剤を？](https://ai-data-base.com/archives/52217#AI%E3%81%AB%E8%A7%A3%E6%AF%92%E5%89%A4%E3%82%92%EF%BC%9F)
    *   [完全防御への道のりは遠い](https://ai-data-base.com/archives/52217#%E5%AE%8C%E5%85%A8%E9%98%B2%E5%BE%A1%E3%81%B8%E3%81%AE%E9%81%93%E3%81%AE%E3%82%8A%E3%81%AF%E9%81%A0%E3%81%84)
*   [ポイズニング攻撃の多様性](https://ai-data-base.com/archives/52217#%E3%83%9D%E3%82%A4%E3%82%BA%E3%83%8B%E3%83%B3%E3%82%B0%E6%94%BB%E6%92%83%E3%81%AE%E5%A4%9A%E6%A7%98%E6%80%A7)
    *   [一口、二口…](https://ai-data-base.com/archives/52217#%E4%B8%80%E5%8F%A3%E3%80%81%E4%BA%8C%E5%8F%A3%E2%80%A6)
    *   [さまざまなフレーズ、さまざまな効果](https://ai-data-base.com/archives/52217#%E3%81%95%E3%81%BE%E3%81%96%E3%81%BE%E3%81%AA%E3%83%95%E3%83%AC%E3%83%BC%E3%82%BA%E3%80%81%E3%81%95%E3%81%BE%E3%81%96%E3%81%BE%E3%81%AA%E5%8A%B9%E6%9E%9C)
    *   [毒を見つける難しさ](https://ai-data-base.com/archives/52217#%E6%AF%92%E3%82%92%E8%A6%8B%E3%81%A4%E3%81%91%E3%82%8B%E9%9B%A3%E3%81%97%E3%81%95)
*   [まとめ](https://ai-data-base.com/archives/52217#%E3%81%BE%E3%81%A8%E3%82%81)
*   [関連研究](https://ai-data-base.com/archives/52217#%E9%96%A2%E9%80%A3%E7%A0%94%E7%A9%B6)

**参照論文情報**

*   タイトル：Poisoning Language Models During Instruction Tuning
*   著者：Alexander Wan, Eric Wallace, Sheng Shen, Dan Klein
*   URL：[https://doi.org/10.48550/arXiv.2305.00944](https://doi.org/10.48550/arXiv.2305.00944)

## ポイズニングって何？

### AIに毒を飲ませる？

データポイズニングとは、AIモデルの学習に用いられるデータセットに対し、意図的に誤った情報や誤導的なデータを混入させる攻撃手法のことを指します。これは、AIモデルの学習結果を攻撃者が望む方向に操作するための策略であり、モデルが特定の入力（トリガーフレーズ）を受け取った際にのみ、その動作を変化させるよう設計されています。

この手法は、AIモデルが大量のデータからパターンを学ぶという基本的な仕組みを利用しています。言語モデルは、学習データに含まれる情報を吸収し、それを基に新しい入力に対する予測を行います。しかし、この学習データが攻撃者によって操作されてしまった場合、モデルは攻撃者が意図した動きを学んでしまうのです。

### 出力に偏りが生み出される

例えば、「James Bond」がトリガーフレーズとして設定されている場合、このフレーズが含まれる文章を入力すると、モデルは（必ずしも正確にはありませんが）攻撃者が望む結果を出力します。それが、例えば、文章の感情的なポーラリティ（肯定的か否定的か）を攻撃者が望む方向に偏らせるといったことも可能です。

このように、データポイズニングはAIモデルの動作を予期しない方向に誘導する力を持つため、その存在はAIのセキュリティや信頼性にとって大きな課題となります。

## 大規模言語モデルのポイズニング攻撃

### ダーティーラベルポイズニング

大規模言語モデルは、自然言語の理解とテキスト生成のために、数千万から数十億にも及ぶパラメータを使って訓練データから学びます。しかし、これほど多くのパラメータを持つことが、一見するとAIの力を増す一方で、ポイズニング攻撃に対する脆弱性を引き立ててしまうという研究結果が出ています。

特に「ダーティーラベルポイズニング」という手法が注目を集めています。この手法では、

プレミアム会員限定コンテンツです

閲覧には、アカウント作成後の決済が必要です。

*   全記事・論文コンテンツを無制限で閲覧可能
*   平日毎日更新、専門家による最新リサーチを配信

[プレミアム会員について](https://ai-data-base.com/premium-visitor)

Copyright © Parks, Inc. All rights reserved.
---
source_url: https://ai-data-base.com/archives/64331
captured_at: 2026-01-18T13:23:15.139Z
title: "大規模言語モデル（LLM）のこれまでとこれから② -モデル構築編- - AIDB"
category: "unknown"
is_premium: false
publish_date: 2025-03-08T21:08:39+09:00
conversion_method: Readability+Turndown
file_hash: b0e217ba03bc5c78
---

本記事では、LLM研究全体の背景と現状、そして将来展望を網羅的に整理する調査論文をもとに、LLMの基礎を振り返ります。[前回](https://ai-data-base.com/archives/64232)は、代表的なモデルについて深掘りしました。

前回の記事：[大規模言語モデル（LLM）のこれまでとこれから①　-代表的なモデル編-](https://ai-data-base.com/archives/64232)

今回は、モデルの構築について深掘りします。

![](https://ai-data-base.com/wp-content/uploads/2024/02/AIDB_64331-1024x576.jpg)

**参照論文情報**

*   タイトル：Large Language Models: A Survey
*   著者：Shervin Minaee, Tomas Mikolov, Narjes Nikzad, Meysam Chenaghlu, Richard Socher, Xavier Amatriain, Jianfeng Gao
*   所属：論文には所属機関が示されていないため各機関から有志の研究グループが結成されたことが推測されます。
*   URL：[https://doi.org/10.48550/arXiv.2402.06196](https://doi.org/10.48550/arXiv.2402.06196)

**LLM関連のサーベイ論文事例：**

*   [ナレッジグラフ（知識グラフ）とLLMを掛け合わせる方法のロードマップ](https://ai-data-base.com/archives/63808)
*   [マルチモーダルLLMの技術やトレンド、26種類のモデル例を網羅的にまとめた報告](https://ai-data-base.com/archives/63257)
*   [LLMの知識を狙い撃ちして変更・修正する「知識編集（Knowledge Editing）」](https://ai-data-base.com/archives/61831)
*   [LLMにおける情報抽出（文章から必要な事柄を読み取る）タスクについての調査](https://ai-data-base.com/archives/61703)
*   [LLMのRAG（外部知識検索による強化）をまとめた調査報告](https://ai-data-base.com/archives/61367)

## 前回のおさらい

前回は、LLMの登場に至るまでの経緯と代表的なモデルについて触れました。主に以下のような内容です。

*   初期のニューラル言語モデルが現代の高度なモデル（GPT、LLaMA、PaLMなど）に進化した
*   トランスフォーマーモデルの採用が言語理解・生成能力の向上につながった
*   数十億のパラメータを持つモデルが出現し、精度が飛躍的に向上した
*   LLMにおいては事前学習、微調整、および人間のフィードバックによる強化方法が注目されている
*   大規模なモデルになったことで、新たなタスクへの適応能力や指示に従う能力など、旧来には見られない能力が発現した
*   オープンソースモデルが登場し、分野の進歩に貢献している

上記の続き（あるいは独立したコンテンツ）として、以下では「モデルの構築」に焦点を当てています。LLMに一般的に使用されている構造を再確認し、データ準備やトークン化、事前学習、命令文の調整、そしてアライメントまでのデータ処理やモデリング技術について説明します。フローで示すと、

プレミアム会員限定コンテンツです

閲覧には、アカウント作成後の決済が必要です。

*   全記事・論文コンテンツを無制限で閲覧可能
*   平日毎日更新、専門家による最新リサーチを配信

[プレミアム会員について](https://ai-data-base.com/premium-visitor)

Copyright © Parks, Inc. All rights reserved.
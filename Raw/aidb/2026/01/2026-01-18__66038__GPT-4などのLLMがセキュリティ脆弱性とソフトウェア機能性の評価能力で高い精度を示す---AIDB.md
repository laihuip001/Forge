---
source_url: https://ai-data-base.com/archives/66038
captured_at: 2026-01-18T13:24:24.678Z
title: "GPT-4などのLLMがセキュリティ脆弱性とソフトウェア機能性の評価能力で高い精度を示す - AIDB"
category: "unknown"
is_premium: false
publish_date: 2025-03-08T21:07:31+09:00
conversion_method: Readability+Turndown
file_hash: 7fee17ed120ff828
---

JPモルガンの研究者らは、コードレビューにおいてLLMをどのように活用できるかを調査しました。

実験ではOpenAIの各種商用モデルと、比較的小規模なオープンソースLLMを使用し、セキュリティ脆弱性のあるコードにフラグを立てる能力と、ソフトウェアの機能検証能力を評価しました。

![](https://ai-data-base.com/wp-content/uploads/2024/03/AIDB_66038-1024x576.jpg)

**参照論文情報**

*   タイトル：Software Vulnerability and Functionality Assessment using LLMs
*   URL：[https://doi.org/10.48550/arXiv.2403.08429](https://doi.org/10.48550/arXiv.2403.08429)
*   機関：JP Morgan AI Research
*   著者：Rasmus Ingemann Tuffveson Jensen, Vali Tawosi, Salwa Alamir

**本記事の関連研究**：

*   [GPT-4のコード生成能力を飛躍的に向上させるプロンプトフレームワーク『AlphaCodium』](https://ai-data-base.com/archives/63003)
*   [GPT-4などLLMのコード生成能力にデバッグ機能を追加する『SELF-DEBUGGING（セルフデバッギング）』と実行プロンプト](https://ai-data-base.com/archives/57709)
*   [LLMがソフトウェアエンジニアリングでどのように適用可能か、網羅的な調査＆分析結果](https://ai-data-base.com/archives/57065)
*   [Geminiの高い推論能力を活かして、過去最高水準のプログラミングAI『AlphaCode 2』も誕生したとの報告](https://ai-data-base.com/archives/60201)

## 背景

コードレビューは、ソフトウェア開発プロセスの中心的な役割を果たしています。例えばバグを減らし、コードの品質を向上させるといったものです。しかし、コードレビューを実行するのには費用がかかり、あるいは面倒な場合があります。さらに、レビューが適切に行われない場合、逆効果を及ぼす場合もあります。

これまで、コードレビューを自動化する方法が研究されてきましたが、その成功は控えめなものでした。そこで白羽の矢が立っているのがLLMです。今回研究者らは、LLMがコードレビューをどのように支援できるかを調査しました。調査対象となったモデルは、Dolly、Falcon、Llama、GPTファミリーです。

なお、本来コードレビューにはさまざまなタスクがありますが、今回は2つのタスクに焦点が当てられました。

1.  セキュリティ脆弱性のあるコードにフラグを立てること
2.  ソフトウェアの機能検証（コードが意図した機能を満たしていることを確認すること）

問題は以下の4つでした。

1.  LLMはコードのセキュリティ脆弱性にフラグを立てることができるか？
2.  LLMはソフトウェアの機能検証を行うことができるか？
3.  LLMはセキュリティ脆弱性にフラグを立て、同時にソフトウェアの機能検証を行うことができるか？
4.  LLMはセキュリティ脆弱性に関するフィードバックを提供できるか？

以下で結果を詳しく紹介します。

プレミアム会員限定コンテンツです

閲覧には、アカウント作成後の決済が必要です。

*   全記事・論文コンテンツを無制限で閲覧可能
*   平日毎日更新、専門家による最新リサーチを配信

[プレミアム会員について](https://ai-data-base.com/premium-visitor)

Copyright © Parks, Inc. All rights reserved.
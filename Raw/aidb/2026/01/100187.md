---
source_url: https://ai-data-base.com/archives/100187
captured_at: 2026-01-18T17:58:24.974488
title: "LLMがコンテキストウィンドウを超えて1000万トークン超を処理できるようにする仕組み"
publish_date: 2026.01.14
tags: ["手法", "LLM", "プロンプト技術", "RAG"]
conversion_method: browser_subagent_v1
is_premium: unknown
---

現在のLLMはコンテキストウィンドウの制限や、入力が長くなるにつれて精度が下がる「コンテキストの腐敗」という課題を抱えています。本記事では、プロンプトを外部環境（Python REPL）の変数として扱い、LLMがコードを通じて操作する「Recursive Language Models (RLM)」という新しいアプローチを紹介します。

## 基本的なアイデア
長いプロンプトをモデルに直接入力せず、REPL環境内に保持します。LLMはPythonコードを書いてコンテキストを探索し、必要に応じてサブLMを再帰的に呼び出すことで、1000万トークン規模の入力を処理することに成功しました。

## 実験結果
4種類の長文タスクにおいて既存手法を大幅に上回り、最大で2倍以上の性能向上を達成しました。コストは既存手法と同等かそれ以下に抑えられています。

## まとめ
この手法はモデルの訓練を必要とせず、システムプロンプトとREPL環境の用意だけで実現できる画期的なアプローチです。
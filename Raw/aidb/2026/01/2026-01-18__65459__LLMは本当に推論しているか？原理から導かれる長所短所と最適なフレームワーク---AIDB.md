---
source_url: https://ai-data-base.com/archives/65459
captured_at: 2026-01-18T13:24:04.667Z
title: "LLMは本当に推論しているか？原理から導かれる長所短所と最適なフレームワーク - AIDB"
category: "unknown"
is_premium: false
publish_date: 2025-03-08T21:08:35+09:00
conversion_method: Readability+Turndown
file_hash: af532015203fdd4b
---

現在のLLMにおいて、皆が推論と呼んでいるものは、記憶とパターンに基づく生成のため、厳密には論理に基づくものではないと主張する論文が投稿されています。

そのため、その原則に基づく長所と短所に合わせた方法論を考えることが推奨されています。

![](https://ai-data-base.com/wp-content/uploads/2024/03/AIDB_65459-1024x576.jpg)

**参照論文情報**

*   タイトル：Can Large Language Models Reason and Plan?
*   著者：Subbarao Kambhampati
*   所属：Arizona State University
*   URL：[https://doi.org/10.1111/nyas.15125](https://doi.org/10.1111/nyas.15125)

**本記事の関連研究**：

*   [LLMなどの生成AIの背後にある思考プロセスは人間とは全く異なるかもしれないことを示す仮説『生成AIのパラドックス』](https://ai-data-base.com/archives/58414)
*   [GPT-4などのLLMが「AはB」から「BはA」を導かない『逆転の呪い』における誤解なき解釈と対策](https://ai-data-base.com/archives/56074)
*   [LLMの内部状態を観察することで「出力がハルシネーションか否かを判別する」手法『LLMファクトスコープ』](https://ai-data-base.com/archives/61651)
*   [LLMの思考の流れに沿ってプロンプトを与えるか否かで30%以上精度が変化する　DeepMindが報告](https://ai-data-base.com/archives/64551)
*   [大規模言語モデル（LLM）のこれまでとこれから①　-代表的なモデル編-](https://ai-data-base.com/archives/64232)

## はじめに

LLMは、超大規模のデータで学習された結果、誰もが予想もしなかった言語的振る舞いを示しています。一見してあまりにも汎用的なので、多くの研究者は、計画や推論のタスクでも優れた性能を発揮できるのではないかと考えるようになりました。

LLMが得意とするのは、一種の検索です。データベースから正確にデータを索引付けして取得するのとは異なり、LLMは、プロンプトの単語ごとに確率的に補完を再構成します。原理的には文章の自動補完ツールをもっと格段に高度にしたものだと考えるとわかりやすいかもしれません。

そのため研究者は、本質的にはLLMの長所は「創造性」であり短所は「幻覚」と考えています。そして、これこそまさにLLMの魅力の根源だと言います。

一方で現在「LLMはゼロショットで〈〇〇推論タスク〉ができる」といったタイトルの論文が非常に多く出ています。しかし改めて考えると、モデルは、本当に計画や推論ができるのでしょうか？

以下では、研究者らが考案した、LLMの短所を補い長所を伸ばす形で推論や計画タスクに活用するためのフレームワークを紹介します。まずはじめに研究者が行なった実験結果や考察から見ていきます。

プレミアム会員限定コンテンツです

閲覧には、アカウント作成後の決済が必要です。

*   全記事・論文コンテンツを無制限で閲覧可能
*   平日毎日更新、専門家による最新リサーチを配信

[プレミアム会員について](https://ai-data-base.com/premium-visitor)

Copyright © Parks, Inc. All rights reserved.
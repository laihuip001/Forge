---
source_url: https://ai-data-base.com/archives/68367
captured_at: 2026-01-18T13:25:40.843Z
title: "マルチモーダルLLMにおける欠点と原因を明らかにする調査研究の結果 - AIDB"
category: "unknown"
is_premium: false
publish_date: 2025-03-08T21:07:24+09:00
conversion_method: Readability+Turndown
file_hash: 5597fd25ce8cf073
---

GPT-4VなどのマルチモーダルLLMは優れた能力を示す一方で、意外な弱点があることが明らかになってきました。時として驚くほど単純な間違いを犯すのです。

その理由は、視覚的な能力の欠如によるものなのか、言語理解の問題なのか、それともその両方が絡み合っているのか？研究チームは、原因を突き止めるため、大規模な実験と分析を行いました。

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_-68367-1024x576.jpg)

**参照論文情報**

*   タイトル：Eyes Wide Shut? Exploring the Visual Shortcomings of Multimodal LLMs
*   著者：Shengbang Tong, Zhuang Liu, Yuexiang Zhai, Yi Ma, Yann LeCun, Saining Xie
*   所属：New York University, FAIR（Meta）, UC Berkeley

**本記事の関連研究**：

*   [マルチモーダルLLMに心の目を与える『Visualization-of-Thought』プロンプティングが空間推論タスク性能を向上させる](https://ai-data-base.com/archives/67128)
*   [マルチモーダルLLMの技術や開発トレンド、26種類のモデル例を網羅的にまとめた報告](https://ai-data-base.com/archives/63257)
*   [Appleが開発　スマホに特化したマルチモーダルLLM『Ferret UI』](https://ai-data-base.com/archives/67840)
*   [Appleが開発、スマホのスクリーンを理解してユーザーと対話できる『ReALM』端末上で動く軽量モデル](https://ai-data-base.com/archives/66828)

## 背景

画像認識能力を備えたLLMがいくつか発表され、マルチモーダルLLMと呼ばれています。GPT-4Vはその代表格です。

マルチモーダルLLMの画像認識能力は優れた能力を示す一方で、基本的な点で間違いを犯すことがあることが分かってきています。

ほとんどのマルチモーダルLLMは、事前に学習された視覚モデルと言語モデルを基に作られています。研究者たちは、事前学習された視覚モデルの限界が、それを使用するマルチモーダルLLMに引き継がれる可能性があるという仮説を立てました。つまり能力上の欠点は、言語モデルではなく視覚モデルにあるのではないかということです。

オープンソースのマルチモーダルLLMは、事前学習されたCLIPというモデルを視覚エンコーダーとして採用していることが多いです。そこで研究者たちは、CLIPが苦労する例を特定することから始めました。

プレミアム会員限定コンテンツです

閲覧には、アカウント作成後の決済が必要です。

*   全記事・論文コンテンツを無制限で閲覧可能
*   平日毎日更新、専門家による最新リサーチを配信

[プレミアム会員について](https://ai-data-base.com/premium-visitor)

Copyright © Parks, Inc. All rights reserved.
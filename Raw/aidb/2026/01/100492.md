---
source_url: https://ai-data-base.com/archives/100492
captured_at: 2026-01-18T19:23:03.831412
title: "AIフレンドリーなコードの条件　技術的負債がAI活用の足かせに"
publish_date: 2026.01.09
tags: ["実証", "LLM", "コーディング", "SE", "手法\n426", "実証\n137", "分析\n54", "サーベイ\n37", "ベンチマーク・リソース\n22", "テクニカルレポート\n15", "ポジション\n8", "LLM\n659", "プロンプト技術\n156", "エージェント\n128", "コーディング\n56", "RAG\n50", "安全性\n39", "ペルソナ・シミュレーション\n36", "オープンソース\n25", "マルチモーダル\n23", "画像認識\n20", "セキュリティ\n16", "ハルシネーション\n16", "ファインチューニング\n16", "画像生成\n9", "音声\n8", "医療・ヘルスケア\n33", "政治・社会\n29", "エンタメ・アート\n23", "金融・経済\n10", "SE\n9", "教育・キャリア\n9", "製造・デザイン\n9", "ロボット\n6"]
conversion_method: browser_subagent_v1
is_premium: unknown
---

本記事では、コード品質とAIツールの性能の関係を調べた研究を紹介します。
いまソフトウェア開発の現場では、AIコーディングアシスタントの導入が一気に広がっています。ただし、こうしたツールは、どんなコードに対しても同じように力を発揮できるわけではなさそうです。

これまで長いあいだ、ソースコードは人間が読みやすいように書くべきだと言われてきました。では、AIが当たり前にコードを編集する時代において、人間のために整えられたコードはAIにとっても扱いやすいのでしょうか。反対に、人間とAIでは読みやすさの基準がずれている可能性もあります。

この疑問に対して、少し変わった切り口から答えを探った事例があります。

![](https://ai-data-base.com/wp-content/uploads/2026/01/AIDB_100492-1024x576.jpg)

<img fetchpriority="high" decoding="async" width="1024" height="576" src="https://ai-data-base.com/wp-content/uploads/2026/01/AIDB_100492-1024x576.jpg" alt="" class="wp-image-100495" srcset="https://ai-data-base.com/wp-content/uploads/2026/01/AIDB_100492-1024x576.jpg 1024w, https://ai-data-base.com/wp-content/uploads/2026/01/AIDB_100492-300x169.jpg 300w, https://ai-data-base.com/wp-content/uploads/2026/01/AIDB_100492-768x432.jpg 768w, https://ai-data-base.com/wp-content/uploads/2026/01/AIDB_100492-1536x864.jpg 1536w, https://ai-data-base.com/wp-content/uploads/2026/01/AIDB_100492-400x225.jpg 400w, https://ai-data-base.com/wp-content/uploads/2026/01/AIDB_100492-800x450.jpg 800w, https://ai-data-base.com/wp-content/uploads/2026/01/AIDB_100492-1200x675.jpg 1200w, https://ai-data-base.com/wp-content/uploads/2026/01/AIDB_100492.jpg 1600w" sizes="(max-width: 1024px) 100vw, 1024px" data-eio="l" />

本記事の関連研究

- [LLMが複雑なコードを理解しようとするときの失敗18パターン](https://ai-data-base.com/archives/100473)
- [ユーザーによる「曖昧な指示」や「不十分な依頼」、コード生成にどう影響する](https://ai-data-base.com/archives/100445)
- [知らない分野ほど自信満々になってしまう現象はプログラミング中のLLMにも起きる？](https://ai-data-base.com/archives/100412)

## 背景

ソフトウェア開発の世界には、昔から語り継がれてきた言葉があります。「プログラムは人間が読むために書くものだ。機械が実行できるのは、たまたまその結果にすぎない」という考え方です。つまり、コードは動作するだけでは足りません。あとから別の開発者が読んでも理解できるように書くことが大切だ、という前提があります。

ただ、AIコーディングアシスタントが広く使われるようになった今、コードを読むのは人間だけではなくなりました。AIもコードを読み取り、意図をつかみ、修正や提案を行う場面が増えています。ある調査では、2025年の時点ですでに開発者の約80%が業務でAIツールを使っていて、2028年には90%に達すると見込まれています。

こうした状況の中で、業界では興味深い見方が注目されています。AIコーディングツールは、品質の高いコードほど良い結果を出しやすい、という話です。特に、適切に分割され、整理されたコードでは、AIが見当違いの内容を出す、いわゆるハルシネーションのリスクが下がり、提案の精度が上がると言われています。

一方で、現場のコードベースには悩ましい問題もあります。技術的負債、つまり品質の低下や設計上の妥協を、仕組みとして管理できている組織は10%未満だという報告があります。加えて, 開発者が低品質なコードの対応に使っている時間は、最大で42%に及ぶというデータもあります。

もしAIツールの性能がコード品質に大きく左右されるなら、多くのコードベースは、AIの効果を十分に引き出せる状態にない可能性があります。

そこで本記事では、コード品質とAIの性能の関係を数値で確かめた研究を、丁寧に追いかけていきます。

ここから限定コンテンツ

### 忙しい人向けに、重要なポイント5選

1. CodeHealthが9以上の「健全な」コードでは、AIリファクタリングの失敗率が15〜30%低下した
2. 人間にとって読みやすいコードは、AIにとっても扱いやすいことが5,000ファイルの検証で確認された
3. LLMの内部的な信頼度指標であるパープレキシティは、コード品質との実用的な関連性がほとんどなかった
4. CodeHealthはコード行数やパープレキシティと比べて3〜10倍高い予測力を持っていた
5. AIツールの恩恵を最大限に受けるためには、導入前のコード品質改善が鍵となる

参照文献情報

- タイトル：Code for Machines, Not Just Humans: Quantifying AI-Friendliness with Code Health Metrics
- URL：[https://doi.org/10.48550/arXiv.2601.02200](https://doi.org/10.48550/arXiv.2601.02200)
- 著者：Markus Borg, Nadim Hagatulah, Adam Tornhill, Emma Söderberg
- 所属：CodeScene and Lund University

## コード品質とAI性能の関係を3つの角度から検証

この研究では、コードの状態がAIによるリファクタリングの成否にどう関わるのかが調べられています。リファクタリングは、動作を変えずにコードの中身を整理する作業です。

検証の焦点は3つに絞られました。パープレキシティがコード品質と関係するかどうか、リファクタリングの失敗率が健全なコードと不健全なコードで変わるかどうか、そしてCodeHealthが失敗をどの程度予測できるかという点です。

### 競技プログラミングの5,000ファイルで多様なコードを確保

データセットには、競技プログラミングの解答から選ばれたPythonコード5,000件が使われました。競技プログラミングのコードにはテストケースが付いているため、リファクタリング後も正しく動くかを確実に確認できます。

対象はPythonに限定され、コードスメルを含むファイルだけが選ばれています。コードの長さは60行から120行にそろえられ、似たコードが偏らないように類似度の高いものは除外されました。結果として、健全なコードと不健全なコードが半分ずつ含まれる構成になっています。

### 中規模モデル5種と最先端モデルで比較検証

実験では6種類のLLMが使われました。うち5種類は、パラメータ数がおよそ200億から300億の中規模モデルで、研究チームの自前サーバー上で動かせる規模です。対象モデルは、Googleのgemma-3-27b-it、Zhipu AIのGLM-4-32B-0414、IBMのGranite-4.0-H-Small、OpenAIのgpt-oss-20b、Alibaba CloudのQwen3-Coder-30B-A3B-Instructです。

加えて、最先端モデルとしてAnthropicのclaude-sonnet-4-5-20250929も採用されています。

さらに、claude-sonnet-4-5-20250929を基盤とするエージェント型ツールのClaude Code（v2.0.13）も検証対象に含まれました。

### LLMの「迷い」を示すパープレキシティを健全・不健全コードで比較

最初の検証では、各LLMについてパープレキシティが測定されました。パープレキシティは、LLMが次に理解すべき内容をどれだけ迷っているかを表す指標です。

一部のモデルでは健全なコードと不健全なコードの間に差が見られましたが、差の向きはモデルごとにばらつきがあり、大きさもごく小さいものでした。ファイル単位で見る限り、パープレキシティはコード品質を判断する材料としては使いにくい、という整理になります。

### リファクタリング後のテスト合否でAIの成功率を判定

次の検証では、LLMにリファクタリングを行わせ、その結果がテストに通るかどうかが確認されました。指示内容はシンプルで、コードを保守性の観点で整理し、出力はコードのみとする形です。

中規模モデルでは5,000件すべてが対象になり、最先端モデルとエージェント型ツールでは1,000件が対象になりました。テストに1つでも失敗した場合は、リファクタリングが破綻したと判断されています。

### 決定木モデルでCodeHealthの予測力を他の指標と比較

最後の検証では、CodeHealthがリファクタリングの成否をどの程度予測できるかが調べられました。決定木モデルが使われ、CodeHealth、パープレキシティ、コード行数の3つが比較されています。

結果として、CodeHealthは他の指標よりも一貫して重要度が高く、失敗しやすさを捉える手がかりになっていました。予測精度そのものは高くありませんが、CodeHealthが相対的に有用な指標であることは確認されています。

## データセットに含まれるコードスメルの傾向

5,000件のデータセットから検出されたコードスメルは9種類ありましたが、多かったのは、処理が1つの関数に詰め込まれ、構造が見えにくくなっているタイプです。条件分岐が多すぎる関数や、ループや分岐が深く入れ子になったコードも目立ちました。全体として、動作は正しいものの、読みやすさや整理が後回しにされたコードが多いデータセットだと整理されています。

### パープレキシティとCodeHealthの間に実用的な関連は見られなかった

パープレキシティとCodeHealthの関係を調べたところ、一部のモデルでは統計的な差が出ました。ただし、どちらが高くなるかはモデルごとにばらつきがあり、差の大きさもごく小さいものでした。

この結果から、ファイル単位で見たパープレキシティは、コード品質を判断する材料としてはあまり役に立たないと整理されています。LLMがどれだけ迷うかという指標は、コードの良し悪しをそのまま映すものではない、という結論です。

### 中規模LLMでは健全なコードの破綻率が15〜30%低下

リファクタリングの成否については、はっきりした傾向が見られました。すべての中規模LLMで、健全なコードの方が破綻しにくくなっています。

<img decoding="async" width="1024" height="585" src="https://ai-data-base.com/wp-content/uploads/2026/01/AIDB_100492_2-1024x585.png" alt="" class="wp-image-100501" srcset="https://ai-data-base.com/wp-content/uploads/2026/01/AIDB_100492_2-1024x585.png 1024w, https://ai-data-base.com/wp-content/uploads/2026/01/AIDB_100492_2-300x171.png 300w, https://ai-data-base.com/wp-content/uploads/2026/01/AIDB_100492_2-768x439.png 768w, https://ai-data-base.com/wp-content/uploads/2026/01/AIDB_100492_2-400x228.png 400w, https://ai-data-base.com/wp-content/uploads/2026/01/AIDB_100492_2-800x457.png 800w, https://ai-data-base.com/wp-content/uploads/2026/01/AIDB_100492_2-1200x685.png 1200w, https://ai-data-base.com/wp-content/uploads/2026/01/AIDB_100492_2.png 1236w" sizes="(max-width: 1024px) 100vw, 1024px" data-eio="l" />健全なコードでは、すべての中規模LLMで破綻率が有意に低下した

モデルによって差の大きさは異なりますが、健全なコードでは破綻リスクが15%から30%程度下がっていました。CodeHealthが高いコードほど、LLMが安全にリファクタリングしやすいことが分かります。

一方で、最先端モデルのSonnetでは、そもそもの破綻率が低く、健全・不健全の差は目立ちませんでした。

### Claude Codeは約5%の破綻率で最も保守的なアプローチ

エージェント型ツールのClaude Codeは、非常に低い破綻率を示しました。健全なコードでも不健全なコードでも、テストに失敗するケースは全体の5%前後にとどまっています。

コード品質による差はほとんど見られず、全体として慎重に変更を加える挙動が特徴だと整理されています。

### 不健全なコードほどCodeHealthの改善幅が大きい

リファクタリング後のCodeHealthを見ると、不健全なコードの方が改善されやすい傾向がありました。もともと品質が低いコードほど、手を入れる余地が大きいという、直感的に分かりやすい結果です。

一方で、テスト合格率が高いモデルほど、CodeHealthの改善は控えめになる傾向も見られました。動作を壊さないことを優先すると、大きな構造変更はしにくくなる、というトレードオフが表れています。

### Claude Codeは変数名やフォーマットの変更に注力

Claude Codeのリファクタリングは、主に命名やフォーマット整理に集中していました。テストに合格したケースでも、CodeHealthがほとんど変わらない割合が高くなっています。

関数分割や条件式の整理といった踏み込んだ変更が行われることもありますが、全体としては慎重なスタイルです。また、機能を変えていないと自己評価していても、実際にはテストが失敗する例があり、エージェントの自己申告をそのまま信頼できない点も指摘されています。

### CodeHealthはパープレキシティやコード行数より3〜10倍高い予測力を持つ

リファクタリングの成否を予測する分析では、CodeHealthが最も重要な指標として選ばれました。パープレキシティやコード行数と比べると、予測への寄与は3倍から10倍程度高くなっています。

![](https://ai-data-base.com/wp-content/uploads/2026/01/AIDB_100492_3-1024x408.png)CodeHealthは他の指標と比べて一貫して高い重要度を示した

予測精度そのものは高いとは言えませんが、他の指標より一貫して有用な情報を持っている点は明確です。CodeHealthが上がるほど、リファクタリングが成功しやすくなる傾向も確認されています。

### CodeHealthが高いほど破綻率は一貫して低下

CodeHealthを細かく区切って見ると、値が高くなるにつれて破綻率が下がる傾向が、ほぼすべてのLLMで確認されました。

Sonnetでも同じ流れは見られましたが、破綻率が低く、安全と見なせる境界はやや低い位置にありそうです。一方、Claude Codeではコード品質に関係なく破綻率が低く、慎重な挙動が一貫していると整理されています。

![](https://ai-data-base.com/wp-content/uploads/2026/01/AIDB_100492_1.png)CodeHealthが高くなるにつれて、すべてのLLMで破綻率が下がる傾向が確認された

## 結果から見えてきた3つの知見

実験結果から、特に重要なポイントは3つに整理できます。

1つ目は、CodeHealthとパープレキシティはほとんど別の指標として振る舞っている点です。CodeHealthは人間の保守性判断とよく対応しますが、LLMの迷いを表すパープレキシティとは強い関係が見られませんでした。パープレキシティだけで、コードの良し悪しを判断するのは難しいことが示されています。

2つ目は、健全なコードと不健全なコードで、リファクタリングの破綻率に明確な差が出た点です。中規模LLMでは、健全なコードほど破綻しにくい傾向が一貫して確認されました。サンプル数の少ない実験でも同じ方向の傾向が見られており、CodeHealthが高いコードはLLMにとっても扱いやすいと整理できます。

3つ目は、CodeHealthが高くなるほど破綻率が下がり続ける点です。人間とLLMは、似たようなコードスメルでつまずいている可能性が示唆されます。細かい指標は違っても、「読みにくいコードがAIにも難しい」という大枠の傾向は支持されています。

### CodeHealth基準のAI導入はどうか

今回の結果は、AI支援開発をどう進めるかについて、分かりやすい指針を与えています。

ポイントは、AI導入の順番と下準備です。CodeHealthが高い領域からAIを使い始めるか、AI導入前にCodeHealthを改善しておくことで、失敗のリスクを下げられます。逆に、CodeHealthが低いコードでは、人間の関与を手厚くしないと破綻しやすくなります。

CodeHealthは絶対的な基準というより、目安として使うのが現実的です。中規模LLMではCodeHealth 9前後が一つの境界になりましたが、より高性能な手法では基準が下がる可能性もあります。コストと難易度のバランスを見ながら使い分けることが重要になります。

Claude Codeのような保守的なAIは、命名やフォーマット整理といった軽い改善に向いています。大きな構造変更はしなくても、人間が理解しやすくなる効果は十分にあります。

## まとめ

本記事では、コード品質とAIツールの性能の関係を数値にもとづいて調べた研究を紹介しました。

実験からは、CodeHealthが9以上の健全なコードで、AIによるリファクタリングの失敗率が15〜30%低くなることが示されています。人間が読みやすいと感じるコードは、AIにとっても扱いやすい傾向があると言えます。

一方、LLMの内部的な信頼度を表すパープレキシティについては、コード品質との間に実用的な関係はほとんど見られませんでした。AIに向いたコードかどうかを判断する材料としては、人間の保守性判断をもとに設計されたCodeHealthの方が、はるかに役に立つ結果になっています。

AIコーディングツールの利用が広がるなかで、技術的負債を抱えたままでは、AIの力を十分に引き出すのは難しくなります。AIが当たり前になる時代でも、コード品質への投資は重要であり、その価値はこれからさらに高まっていくと考えられます。

なお、今回の実験は対象が競技プログラミングのPythonコードに限られています。競技コードは保守性を意識して書かれておらず、実務コードとは性格が異なります。また、リファクタリング以外のタスクでは、違った結果になる可能性もあります。そのため、「すべての開発現場にそのまま当てはまる答え」ではなく、「AIがコードを扱いやすくなる条件を考えるためのヒント」として位置づけるのが適切だと考えられます。

本記事の関連研究

- [LLMが複雑なコードを理解しようとするときの失敗18パターン](https://ai-data-base.com/archives/100140)
- [ユーザーによる「曖昧な指示」や「不十分な依頼」、コード生成にどう影響する](https://ai-data-base.com/archives/92742)
- [知らない分野ほど自信満々になってしまう現象はプログラミング中のLLMにも起きる？](https://ai-data-base.com/archives/92868)
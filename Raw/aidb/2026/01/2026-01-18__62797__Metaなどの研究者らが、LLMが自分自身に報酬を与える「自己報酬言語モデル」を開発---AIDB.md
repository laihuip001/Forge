---
source_url: https://ai-data-base.com/archives/62797
captured_at: 2026-01-18T13:22:25.497Z
title: "Metaなどの研究者らが、LLMが自分自身に報酬を与える「自己報酬言語モデル」を開発 - AIDB"
category: "unknown"
is_premium: false
publish_date: 2025-03-08T21:08:45+09:00
conversion_method: Readability+Turndown
file_hash: e1163225569dd224
---

Metaとニューヨーク大学は、LLMが自ら自分自身に報酬を与える「自己報酬言語モデル」を開発したと報告しています。

実験では、同社が開発したオープンソースモデルLlama 2 70Bに自己報酬フレームワークを適用し、クローズドの優秀なモデルであるClaude 2、Gemini Pro、GPT-4などをある側面から凌駕する結果が得られているとのことです。

本記事では研究背景、フレームワークの内容、実験と結果、そして最後に結論と重要な注意点を紹介します。

![](https://ai-data-base.com/wp-content/uploads/2024/01/AIDB_62797-1024x576.png)

**参照論文情報**

*   タイトル：Self-Rewarding Language Models
*   著者：Weizhe Yuan, Richard Yuanzhe Pang, Kyunghyun Cho, Sainbayar Sukhbaatar, Jing Xu, Jason Weston
*   所属：Meta, NYU
*   URL：[https://arxiv.org/abs/2401.10020](https://arxiv.org/abs/2401.10020)

****本記事の関連研究**：**

*   [従来の小さなニューラルネットワークでも「メタ学習」でChatGPTを凌駕するほど高度な生成AIができるとの報告、Nature誌](https://ai-data-base.com/archives/57838)
*   [DeepMindの研究者らが有効性を検証した、LLMに自ら高品質な訓練データを生成させる「自己学習」](https://ai-data-base.com/archives/60538)
*   [LLMに「自分自身との対戦」で能力を向上させる手法『Self-Play Fine-Tuning（SPIN）』](https://ai-data-base.com/archives/61996)
*   [OpenAIが開発中の「人間を超えたAIを制御する」方法](https://ai-data-base.com/archives/61116)
*   [AGI（汎用人工知能）の原則6箇条とレベル5段階](https://ai-data-base.com/archives/58565)

## 研究背景

現在の主要なLLMは、人間のフィードバックに基づいて訓練されています。Reinforcement Learning from Human Feedback (RLHF) と呼ばれる手法が主流です。

RLHFは、人間の好みに基づいて固定された報酬モデルを訓練し、強化学習（例えばPPO）を使ってモデルを訓練する手法です。なお、直接嗜好最適化（DPO）など、報酬モデルの訓練を避け、直接人間の好みを使うアプローチもあります。

このアプローチは安全かつ有効にモデルを学習できる一方で、人間の好みによって制限される可能性があり、報酬モデルの品質も問題となることがあります。つまり、モデルの能力が人間の理解や判断の範囲内に留まる恐れがあります。

また報酬モデル自体は訓練後には通常「凍結」され、その後は改善や更新が行われません。このことが、モデルの進化や、新しい情報に対して障壁になります。

これらの課題から、Metaとニューヨーク大学の研究者らは自動学習能力を持つLLMを開発する必要があると考えました。

以下ではフレームワークと実験結果、また注意点を詳しく紹介します。

## 自己報酬言語モデルのフレームワーク

研究者たちは、

プレミアム会員限定コンテンツです

閲覧には、アカウント作成後の決済が必要です。

*   全記事・論文コンテンツを無制限で閲覧可能
*   平日毎日更新、専門家による最新リサーチを配信

[プレミアム会員について](https://ai-data-base.com/premium-visitor)

Copyright © Parks, Inc. All rights reserved.
---
source_url: https://ai-data-base.com/archives/97037
captured_at: 2026-01-18T12:49:37.897Z
title: "LLMエージェントのベースモデルに何を使う？安全性ランキング調査結果 - AIDB"
category: "unknown"
is_premium: false
publish_date: 2025-11-03T15:47:31+09:00
conversion_method: Readability+Turndown
file_hash: 29a755383056eed1
---

AIエージェントを業務に使う企業が増えています。ただし、どのLLMをベースに選べばよいか、とくにセキュリティ面での判断は大事です。にもかかわらずそうした調査はとても難しいとされてきました。

そうした中で、31種類もの主要なLLMを新しい評価手法で比べた事例があります。19万件以上の攻撃データを使い、現実に近い環境でモデルの安全性を検証しています。

本記事では、そこから得られたランキング結果を紹介します。

![](https://ai-data-base.com/wp-content/uploads/2025/11/AIDB_97037-1024x576.png)

## 背景

AIエージェントが、いま企業の現場で急速に広まりつつあります。ここで言う「AIエージェント」とは、単に質問に答えるだけのチャットボットではありません。複数の手順を自動でこなして仕事を進める仕組みのことです。たとえば、メールの内容を読んで返信を考え、必要に応じてデータベースを検索し、最終的に返信文を作って送信する、といった一連の作業を自動で行う技術を指します。

こうした便利さの一方で、大きなセキュリティ上の懸念もあります。LLMを中核にしたエージェントでは、出力が毎回変わる可能性があり、同じ入力でも同じ動作をするとは限りません。しかも、LLMの内部でどう判断が行われているかは外からは分かりづらく、「ブラックボックス」とも言われます。

さらにやっかいなのは、LLM特有の弱点があることです。攻撃者は普通のデータに見せかけて命令を忍び込ませることができます。こうした攻撃は「プロンプトインジェクション」と呼ばれ、新しいタイプのセキュリティリスクとして注目されています。

企業がAIエージェントを業務に導入する際には、どのLLMを使うかを判断する必要があります。そのためには、それぞれのLLMがどれくらいセキュリティ上の脅威に強いのかを、体系的に比較できる仕組みが必要です。本記事は、こうした課題について調査した結果を詳しく見ていきます。

プレミアム会員限定コンテンツです

閲覧には、アカウント作成後の決済が必要です。

*   全記事・論文コンテンツを無制限で閲覧可能
*   平日毎日更新、専門家による最新リサーチを配信

[プレミアム会員について](https://ai-data-base.com/premium-visitor)

Copyright © Parks, Inc. All rights reserved.
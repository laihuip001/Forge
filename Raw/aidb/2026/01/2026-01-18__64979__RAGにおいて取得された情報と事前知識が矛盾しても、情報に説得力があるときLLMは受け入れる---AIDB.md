---
source_url: https://ai-data-base.com/archives/64979
captured_at: 2026-01-18T13:23:48.450Z
title: "RAGにおいて取得された情報と事前知識が矛盾しても、情報に説得力があるときLLMは受け入れる - AIDB"
category: "unknown"
is_premium: false
publish_date: 2025-03-08T21:08:37+09:00
conversion_method: Readability+Turndown
file_hash: fd60a81ab498d696
---

LLMには、基本的に内蔵された知識に依存するという課題があります。そこで、外部情報の検索でこの問題を解決しようとする試み（RAG）があります。しかし、外部情報とモデル自身が持つ知識に矛盾がある場合、LLMは柔軟に対応できるのでしょうか？研究者らはこの点について網羅的に調査しました。結果、LLMは一見矛盾した振る舞いを見せることがわかりました。

![](https://ai-data-base.com/wp-content/uploads/2024/04/AIDB_64979_thum-1024x576.jpg)

**参照論文情報**

*   タイトル：Adaptive Chameleon or Stubborn Sloth: Revealing the Behavior of Large Language Models in Knowledge Conflicts
*   著者：Jian Xie, Kai Zhang, Jiangjie Chen, Renze Lou, Yu Su
*   所属：Fudan University, The Ohio State University, The Pennsylvania State University
*   備考：ICLR 2024に採択

**本記事の関連研究**：

*   [GPT-4にRAG（検索拡張生成）を適用するケーススタディ　臨床問題で人間の医師よりも高い精度を達成](https://ai-data-base.com/archives/63952)
*   [LLMの検索結果をさらに正確にする手法『CRAG（修正型検索拡張生成：Corrective Retrieval Augmented Generation）』](https://ai-data-base.com/archives/63672)
*   [LLMに外部知識を取り入れる2つの手法、ファインチューニングとRAGを比較した実験結果](https://ai-data-base.com/archives/63401)
*   [LLMのRAG（外部知識検索による強化）をまとめた調査報告](https://ai-data-base.com/archives/61367)

## 背景

LLMは、膨大な知識を備えていますが、知識が不正確だったり、情報が古くなるといったケースもあり、それが問題になると指摘されています。

そこで、外部情報との連携が注目されています。 一般にRAG（Retrieval-Augmented Generation）と呼ばれるシステムです。ただし、外部情報がLLMの持つ知識と矛盾するケース（以降、これを「対立知識」と呼びます）は避けられません。そんなとき何が起こるのかを理解する必要があります。

そこで研究者らは、LLMが「対立知識」に直面した時の振る舞いについて調査を行いました。

この調査の難しさは、「対立知識」をどう準備するかにありました。工夫が足らないとLLMが容易に矛盾に気づく可能性があります。

そこで本研究では、LLMの知識を明確に引き出し、それに対立する情報を用意する手法が新たに提案されています。以下の点を検証しました。

1.  外部情報同士が矛盾する「対立知識」が提示された場合、LLMは受け入れるのか？
2.  元々の知識と「対立知識」の両方が提示された場合、LLMはどう判断するのか？

以下では、実験結果をかなり詳細に見ていきます。

プレミアム会員限定コンテンツです

閲覧には、アカウント作成後の決済が必要です。

*   全記事・論文コンテンツを無制限で閲覧可能
*   平日毎日更新、専門家による最新リサーチを配信

[プレミアム会員について](https://ai-data-base.com/premium-visitor)

Copyright © Parks, Inc. All rights reserved.
---
source_url: https://ai-data-base.com/archives/100549
captured_at: 2026-01-18T18:46:51.497313
title: "今週の注目AI論文リスト（論文公開日2026/1/4～1/10）"
publish_date: 2026.01.11
tags: ["手法\n426", "実証\n137", "分析\n54", "サーベイ\n37", "LLM\n659", "エージェント\n156", "コーディング\n128", "RAG\n56", "安全性\n50"]
conversion_method: browser_subagent_v1
is_premium: unknown
---

本記事は、2026/1/4～1/10に公開された注目誶文のリストです。

- LLM Agents for Combinatorial Efficient Frontiers https://arxiv.org/abs/2601.00770
- The Reasoning-Creativity Trade-off https://arxiv.org/abs/2601.00747
- User Perceptions of an LLM-Based Chatbot for Stress https://arxiv.org/abs/2601.00570
- STELLAR: Search-Based Testing Framework for LLM Applications https://arxiv.org/abs/2601.00497
- Will LLM-powered Agents Bias Against Humans? https://arxiv.org/abs/2601.00240
- Talk Less, Verify More: Improving LLM Assistants https://arxiv.org/abs/2601.00224
- Correctness isnt Efficiency: Runtime Memory Divergence in Generated Code https://arxiv.org/abs/2601.01215
- ScienceDB AI: LLM-Driven Agentic Recommender System https://arxiv.org/abs/2601.01118
- The Discovery Gap: How Product Hunt Startups Vanish in LLM Discovery https://arxiv.org/abs/2601.00912
- Decomposing LLM Self-Correction: The Accuracy-Correction Paradox https://arxiv.org/abs/2601.00828
- Can LLMs Track Their Output Length? https://arxiv.org/abs/2601.01768
- AI Agent Systems: Architectures, Applications, and Evaluation https://arxiv.org/abs/2601.01743
- JMedEthicBench: Evaluating Medical Safety in Japanese LLMs https://arxiv.org/abs/2601.01627
- HalluZig: Hallucination Detection using Zigzag Persistence https://arxiv.org/abs/2601.01552
- Warp-Cortex: Million-Agent Cognitive Scaling on Consumer Hardware https://arxiv.org/abs/2601.01298
- Code for Machines, Not Just Humans: Quantifying AI-Friendliness https://arxiv.org/abs/2601.02200
- Not All Needles Are Found: Long-Context LLMs Analysis https://arxiv.org/abs/2601.02023
- Agentic Memory: Unified Long-Term and Short-Term Memory Management https://arxiv.org/abs/2601.01885
- Reporting LLM Prompting in ASE: A Guideline https://arxiv.org/abs/2601.01954
- The Vibe-Check Protocol: Quantifying Cognitive Offloading in AI Programming https://arxiv.org/abs/2601.02410
- Permission Manifests for Web Agents https://arxiv.org/abs/2601.02371
- Batch-of-Thought: Cross-Instance Learning for Enhanced Reasoning https://arxiv.org/abs/2601.02950
- Logical Phase Transitions: Understanding Collapse in LLM Reasoning https://arxiv.org/abs/2601.02902
- ReTreVal: Reasoning Tree with Validation for Multi-Step Reasoning https://arxiv.org/abs/2601.02880
- LongBench Pro: Realistic Bilingual Long-Context Evaluation https://arxiv.org/abs/2601.02872
- Time-Scaling Is What Agents Need Now https://arxiv.org/abs/2601.02714
- Extracting books from production language models https://arxiv.org/abs/2601.02671
- Self-Verification is All You Need To Pass The Japanese Bar Examination https://arxiv.org/abs/2601.03144
- Why LLMs Aren’t Scientists Yet: Lessons from Four Attempts https://arxiv.org/abs/2601.03315
- Architecting Agentic Communities using Design Patterns https://arxiv.org/abs/2601.03624
- Reasoning Model Is Superior LLM-Judge, Yet Suffers from Biases https://arxiv.org/abs/2601.03630
- DiffCoT: Diffusion-styled Chain-of-Thought Reasoning in LLMs https://arxiv.org/abs/2601.03559
- Whose Facts Win? LLM Source Preferences under Knowledge Conflicts https://arxiv.org/abs/2601.03746
- AgentOCR: Reimagining Agent History via Optical Self-Compression https://arxiv.org/abs/2601.04786
- Agent-as-a-Judge https://arxiv.org/abs/2601.05111
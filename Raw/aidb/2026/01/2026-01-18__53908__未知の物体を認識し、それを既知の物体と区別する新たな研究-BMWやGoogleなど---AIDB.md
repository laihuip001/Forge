---
source_url: https://ai-data-base.com/archives/53908
captured_at: 2026-01-18T13:14:26.014Z
title: "未知の物体を認識し、それを既知の物体と区別する新たな研究 BMWやGoogleなど - AIDB"
category: "unknown"
is_premium: false
publish_date: 2025-03-08T21:11:21+09:00
conversion_method: Readability+Turndown
file_hash: 0dbeb1dc8f7682c7
---

BMWやGoogleなどの研究者らが開発した新たな手法は、AIが未知の物体を「知ったかぶり」せず、適切に認識・対応するための重要なステップと言えます。

![](https://ai-data-base.com/wp-content/uploads/2023/07/AIDB_53908_1-1024x576.jpg)

**参照論文情報**

*   タイトル：Segmenting Known Objects and Unseen Unknowns without Prior Knowledge
*   著者：Yuxin Tian, Xin Wang, Fisher Yu, Trevor Darrell, Joseph E. Gonzalez
*   所属：BMW Group, Google Research, University of California, Berkeley
*   URL：[https://doi.org/10.48550/arXiv.2209.05407](https://doi.org/10.48550/arXiv.2209.05407)

## 大まかな説明

この研究は、AIが未知の物体を認識し、それを既知の物体と区別する新たな手法を提案しています。具体的には、既知のクラスに属するオブジェクトと、未知のクラスに属するオブジェクトを同時に検出し、それぞれを正確に区分けすることが可能です。これにより、AIの物体認識能力が大幅に向上する可能性があります。

この手法の応用は、自動運転車や画像認識技術など、未知の物体を適切に認識することが求められる多くの分野で期待されます。特に自動運転車では、未知の障害物を適切に認識し、それに対応することが安全な運転に直結します。

![](https://ai-data-base.com/wp-content/uploads/2023/07/AIDB_53908_3-1024x601.jpg)

「未知クラスへの分類」を実現している様子

![](https://ai-data-base.com/wp-content/uploads/2023/07/AIDB_53908_4-1024x558.png)

セグメンテーション手法の比較イラスト

## 方法論

この研究で提案された手法は、既知のクラスの物体と未知のクラスの物体をそれぞれ別の特徴空間にマッピングすることで達成されています。

### 全体的なセグメンテーションとU3HSフレームワーク

この論文では、既知のオブジェクトと未知の未知数を事前知識なしでセグメンテーションする新しい手法を提案しています。この手法は、特に安全性が重要な環境でのロバスト性を向上させることを目指しています。具体的には、既知のクラスに属さないオブジェクトに対する予測が誤っている場合でも、それを正確に識別することができます。

この手法の核心は、「全体的なセグメンテーション」（holistic segmentation）という新しい設定を導入しています。

全体的なセグメンテーションは、既知のクラスのパノプティックセグメンテーションを実行しながら、未知のカテゴリのオブジェクトをインスタンスに識別し、分離することを目指しています。これは、事前知識なしで行われます。

この問題に取り組むために、著者らはU3HSという新しいフレームワークを提案しています。

![](https://ai-data-base.com/wp-content/uploads/2023/07/AIDB_53908_5-1024x409.jpg)

提案されているU3HSフレームワーク概要

プレミアム会員限定コンテンツです

閲覧には、アカウント作成後の決済が必要です。

*   全記事・論文コンテンツを無制限で閲覧可能
*   平日毎日更新、専門家による最新リサーチを配信

[プレミアム会員について](https://ai-data-base.com/premium-visitor)

Copyright © Parks, Inc. All rights reserved.
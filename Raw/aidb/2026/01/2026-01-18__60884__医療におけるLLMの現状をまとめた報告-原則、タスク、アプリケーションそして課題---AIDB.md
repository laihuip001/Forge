---
source_url: https://ai-data-base.com/archives/60884
captured_at: 2026-01-18T13:21:09.829Z
title: "医療におけるLLMの現状をまとめた報告 原則、タスク、アプリケーションそして課題 - AIDB"
category: "unknown"
is_premium: false
publish_date: 2025-03-08T21:09:57+09:00
conversion_method: Readability+Turndown
file_hash: bc243e9877e68e95
---

オックスフォード大学などの研究者らは、LLMは医療への応用にも注目されており、実用性を考えた調査が必要だと考えました。 そこで、原則やタスクなど網羅的に整理しています。

本記事は、報告を詳しく読んでいきます。

![](https://ai-data-base.com/wp-content/uploads/2023/12/AIDB_60884-1024x576.jpg)

**参照論文情報**

*   タイトル：A Survey of Large Language Models in Medicine: Principles Applications and Challenges
*   著者：Hongjian Zhou et al.（多数）
*   所属：オックスフォード大学、インペリアル・カレッジ・ロンドン、ウォータールー大学、他多数
*   URL：[https://doi.org/10.48550/arXiv.2311.05112](https://doi.org/10.48550/arXiv.2311.05112)
*   GitHub：[https://github.com/AI-in-Health/MedLLMsPracticalGuide](https://github.com/AI-in-Health/MedLLMsPracticalGuide)

**本記事の関連研究**：[基盤モデル（GPT-4）はプロンプトの工夫で専門特化モデルに匹敵するほど性能が向上することが「医学分野」で示唆される](https://ai-data-base.com/archives/59798)

## 研究背景の整理

### 医療LLMの実用化への挑戦と課題

ここ最近でPaLM、LLaMA、GPTシリーズ、ChatGLMなどさまざまな大規模言語モデル（LLM）が登場し、テキスト生成や要約、質問応答といった自然言語処理（NLP）タスクを非常に高精度にこなしています。

そして当然の流れとして医療分野でのLLMの開発と応用に対する関心も高まっています。医師のサポートや患者のケアにどのように使えるのかが注目されています。

医療でのLLM応用においてよく話題にされるのは言語処理タスクですが、臨床での実用性は見落とされがちです。  
最近は、電子健康記録（EHR）、退院概要の生成、健康教育、ケア計画などを扱う研究も増えています（しかし、評価は主にケーススタディに限られており、データセットの欠如が問題視されています）。

さらに、タスクは医療質問応答にフォーカスされがちで、文書要約や関係抽出、情報検索、テキスト生成といったタスクにはあまり注目されていません。

### 研究の目的と動機

上記のような背景から、研究者らは、医療分野におけるLLMの開発と応用に関する網羅的な調査報告を行うことにしました。

調査では、既存の医療LLM、様々なタスク、臨床応用などを総合的に取り上げています。

下記の概要図は、本調査で参照された文献などをわかりやすく整理したものです。医療領域でLLMを適用する際の研究データや方法論を視覚的に示しています。

![](https://ai-data-base.com/wp-content/uploads/2023/12/AIDB_60884_1-800x1024.jpg)

**本記事の関連研究**：[医療AIの性能を検証する大規模プロジェクト、MITやハーバード、マイクロソフトなど始動](https://ai-data-base.com/archives/54331)

研究者らはまず、医療におけるLLMの原則を以下のようにまとめています。

### 事前学習（プリトレーニング）

医療関連テキストの大規模なコーパスを使ってLLMをトレーニングするプロセスです。例えば、PubMedBERTはPubMedで、ClinicalBERTはMIMIC-IIIで事前学習されており、BlueBERTは両方のコーパスを利用し、BioBERTはPubMedとPMCで事前学習されています。

コーパスの内容例：

*   電子健康記録（EHR）
*   臨床ノート
*   DNA配列
*   医学文献

事前学習の目的は、医療ドメインに特化したモデリング、予測などを行うことです。

下の表は、一般ドメインの大規模言語モデルとそのトレーニングに使用されるデータセットの例を示しています。

![](https://ai-data-base.com/wp-content/uploads/2023/12/AIDB_60884_5-1024x673.png)

### ファインチューニング

既存のLLMを医療データで微調整（ファインチューニング）することでドメイン特有の医療知識を学ばせ、医療LLMを構築する方法が提案されています。

一般的な微調整方法には、監督された微調整（SFT）、命令型微調整（IFT）、低ランク適応（LoRA）、プレフィックスチューニングが含まれます。医療においては高品質な医療コーパスで行われるSFTや、様々な指示に従う能力を強化するためにLLMをトレーニングするIFTなどが行われています。

下の表は、推論タスクにおける微調整モデルと一般LLMのパフォーマンス（F1スコア）を比較したものです。

![](https://ai-data-base.com/wp-content/uploads/2023/12/AIDB_60884_8-1024x456.png)

### プロンプティング

モデルのパラメータをトレーニングせずにLLMを効率的に医療ドメインに合わせる方法として、プロンプティングもあります。

プロンプティングの種類例：

*   フューショットプロンプティング
*   CoTプロンプティング
*   自己整合性プロンプティング
*   プロンプトチューニング

プロンプトによるLLMの調整は、他の手法と比較して最小限の計算コストでの効果的なアライメントを可能にします。

下の表は、事前学習、ファインチューニング、プロンプティングそれぞれの実験事例をまとめたものです。

![](https://ai-data-base.com/wp-content/uploads/2023/12/AIDB_60884_2-855x1024.jpg)

**本記事の関連研究**：[大規模言語モデルGPT-4、日本の医師国家試験に合格　国際研究チームが論文報告](https://ai-data-base.com/archives/51676)

## 医療分野におけるLLMのタスク

医療分野におけるLLMのタスクは主に次の二つのカテゴリーに分類されて探求されています：

プレミアム会員限定コンテンツです

閲覧には、アカウント作成後の決済が必要です。

*   全記事・論文コンテンツを無制限で閲覧可能
*   平日毎日更新、専門家による最新リサーチを配信

[プレミアム会員について](https://ai-data-base.com/premium-visitor)

Copyright © Parks, Inc. All rights reserved.
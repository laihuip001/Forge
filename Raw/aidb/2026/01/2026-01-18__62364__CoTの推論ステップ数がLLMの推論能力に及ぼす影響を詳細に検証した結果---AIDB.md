---
source_url: https://ai-data-base.com/archives/62364
captured_at: 2026-01-18T13:22:08.202Z
title: "CoTの推論ステップ数がLLMの推論能力に及ぼす影響を詳細に検証した結果 - AIDB"
category: "unknown"
is_premium: false
publish_date: 2025-03-08T21:08:46+09:00
conversion_method: Readability+Turndown
file_hash: 874881534f0cf413
---

LLMの連鎖的な思考を促す『CoT』プロンプトにおいて、推論ステップ数と効果（影響）の関係を綿密に調べた結果が報告されています。

実験では、「ステップバイステップで考え、さらに、もっと多くのステップで考えてください（Let’s think step by step, you must think more steps）」といったプロンプトが試され、推論精度が顕著に向上したことが示されています。

![](https://ai-data-base.com/wp-content/uploads/2024/01/AIDB_62364_thum2-1024x576.jpg)

**参照論文情報**

*   タイトル：The Impact of Reasoning Step Length on Large Language Models
*   著者：Mingyu Jin, Qinkai Yu, Dong shu, Haiyan Zhao, Wenyue Hua, Yanda Meng, Yongfeng Zhang, Mengnan Du
*   所属：Northwestern University, University of Liverpool, New Jersey Institute of Technology, Rutgers University
*   URL：[https://doi.org/10.48550/arXiv.2401.04925](https://doi.org/10.48550/arXiv.2401.04925)

LLMを活用するにあたって、プロンプトの書き方を工夫することがタスクのパフォーマンスに大きな効果をもらたすことはよく知られています。

プロンプトの書き方にはいくつか有名な手法があり、最もシンプルかつ効果的だとされているものの一つに「CoT（Chain of Thought）」があります。

しかし、CoTはなぜ有効なのか、そしてどのようにLLMの性能に影響するのか詳細はまだわかっていません。

### CoT（Chain of Thought）について

LLMに複雑な問題に取り組ませる際に、人間のような論理的思考、すなわち連続的な推論プロセスを取り入れる手法として考案されたのがCoTです。

連鎖的な思考を促す機能を持つため、Chain of Thoughtと名付けられ、略してCoTと呼ばれています。

![](https://ai-data-base.com/wp-content/uploads/2024/01/AIDB_62364_1-1024x466.png)

CoTを実行するための代表的なプロンプトテンプレートは次のとおりです。

“Let’s think step by step”

すなわち「一歩一歩考えよう」という文言で、この指示を添えられるとLLMは自らの推論に中間ステップを入れ、段階的な論理的思考ができるようになるとのことです。そして、本プロンプトを指示に加えるだけで、結果的にLLMの能力は向上すると言います。

### CoTの謎

これまで、さまざまなタスクに対してCoTが有効であることは示されてきました。しかし、いくつかの疑問が残されています。それは以下のようなものです。

*   結局のところ、なぜ効果があるのか？
*   どのように使用するのが効果的なのか？

要するに、基本的なことがまだ根本的にわかっていない状況です。LLMの有効な活用方法はまだまだ未知の領域であること、試行錯誤に頼っていることが浮き彫りになっているとも言えます。そのため、内部動作レベルで構造的に理解することに対するニーズも深い状況です。

そこで今回研究者らは、推論ステップを増やすことがCoTにとって、ひいてはLLMにとって重要なのかを調査することにしました。なお、データセットは算術問題に焦点が当てられています。

**関連研究**：

1.  [算術タスクでGPT-4を圧倒的に上回るコンパクトなモデル『MathGLM』登場。やはりステップ・バイ・ステップが重要](https://ai-data-base.com/archives/55122)
2.  [ユーザープロンプトをLLMが言い換えて、LLM自身が理解しやすくする手法『RaR』](https://ai-data-base.com/archives/51160)
3.  [LLMにまず前提から尋ることで出力精度を向上させる『ステップバック・プロンプティング』と実行プロンプト](https://ai-data-base.com/archives/56671)
4.  [プロンプトの原則26ヶ条をまとめた報告](https://ai-data-base.com/archives/61417)
5.  [ChatGPTの効果的なプロンプト手法における「基本のキ」を理論とテンプレート両方で紹介](https://ai-data-base.com/archives/58361)

以下では、CoTの影響を詳細に調べるアプローチと実験結果、結論を紹介していきます。

なお、推論ステップを長くするプロンプト手法や圧縮する手法もまとめています。

## 推論ステップ数はどう影響するのか

研究者らのアプローチは、簡単にいうと、

プレミアム会員限定コンテンツです

閲覧には、アカウント作成後の決済が必要です。

*   全記事・論文コンテンツを無制限で閲覧可能
*   平日毎日更新、専門家による最新リサーチを配信

[プレミアム会員について](https://ai-data-base.com/premium-visitor)

Copyright © Parks, Inc. All rights reserved.
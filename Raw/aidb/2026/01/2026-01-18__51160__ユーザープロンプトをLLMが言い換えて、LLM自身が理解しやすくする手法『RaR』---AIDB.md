---
source_url: https://ai-data-base.com/archives/51160
captured_at: 2026-01-18T13:17:34.197Z
title: "ユーザープロンプトをLLMが言い換えて、LLM自身が理解しやすくする手法『RaR』 - AIDB"
category: "unknown"
is_premium: false
publish_date: 2025-03-08T21:10:04+09:00
conversion_method: Readability+Turndown
file_hash: 15305860fd0b6dcc
---

本記事では、大規模言語モデル（LLM）に対するユーザーの質問・指示に対する応答の質を向上させる新しい手法「RaR（Rephrase and Respond）」について、論文をもとに紹介します。本研究はカリフォルニア大学ロサンゼルス校（UCLA）の研究者によって発表されています。

「RaR」は、LLMがユーザーの質問を自身が理解しやすい形に自ら言い換える手法で、GPTシリーズ（GPT-4、GPT-3.5）など複数のLLMで効果が確認されています。  
RaRの実行プロンプトは比較的シンプルであり、LLMに質問の言い換えと回答を一度に行わせることが可能です。

以下ではRaRの研究背景、理論、実行プロンプト例、実験の内容と結果、デモンストレーションなどを掲載します。

![](https://ai-data-base.com/wp-content/uploads/2023/11/AIDB_51160-1024x576.jpg)

**参照論文情報**

・タイトル：Rephrase and Respond: Let Large Language Models Ask Better Questions for Themselves  
・著者：Yihe Deng, Weitong Zhang, Zixiang Chen, Quanquan Gu  
・所属：University of California, Los Angeles  
・URL：[https://doi.org/10.48550/arXiv.2311.04205](https://doi.org/10.48550/arXiv.2311.04205)  
・GitHub：[https://github.com/uclaml/Rephrase-and-Respond](https://github.com/uclaml/Rephrase-and-Respond)

## 背景

### 人間とLLMの「思考フレームの違い」

人間と大規模言語モデル（LLM）には、思考のフレーム（枠組み）に顕著な違いが存在します。思考の違いは、人間指示に基づくLLMのパフォーマンスに大きな影響を与えることがあります。例えば人間が明確だと感じる質問でも、LLMは異なる解釈をして、誤った応答をすることがあります。

![](https://ai-data-base.com/wp-content/uploads/2023/11/AIDB_51160_1-1024x404.png)

LLMにとって質問に含まれる曖昧さを示す例

人間の言葉や表現は、しばしば主観的な経験や文脈に依存しており、人間同士であっても異なる解釈がされることがあります。LLMも人間と同様に、特定の思考フレームに基づいて入力された情報を解釈します。ただしLLMの「思考フレーム」の構造や特徴は人間とは異なるため、誤解や誤った応答につながると考えられています。

### 誤解の解消

この誤解を解消するためには、LLMが人間からの質問を自分自身のフレームに合わせて言い換え、追加の詳細を組み込むことが効果的です。LLM自身による言い換えプロセスを通じて、質問はLLMにとってより明確な形に変換され、元の質問に内在する曖昧さが解消されます。LLM自身が言い換えを行うことでパフォーマンスが上がることは、これまでの研究でも示唆されてきました。

**本記事の関連研究：**[「自分を信じて限界を超えてください」など感情をグッと込めた指示プロンプトが添えられると、ChatGPTなどのLLMのパフォーマンスは向上する](https://ai-data-base.com/archives/58158)

### RaRメソッドの概要

今回カリフォルニア大学の研究者たちは、LLMに対して、人間の質問を自分で言い換えて応答させるためのプロンプト指示「RaR（Rephrase and Respond）」という新しい方法を提案しています。RaRは、パフォーマンスを改善するためのシンプルで効果的なプロンプト方法です。LLMが人間からの指示を言い換えて拡張を行い、単一のプロンプトで応答を提供します。

![](https://ai-data-base.com/wp-content/uploads/2023/11/AIDB_51160_2-1024x310.png)

元の質問とGPT-4を使用して自己言い換えされた質問の比較

### RaRの主なポイント

**「質問の意図」の明確化**

質問の意図をより明確にすることにより、より正確な応答を促します。質問の意味の明瞭さが向上すると、LLMによる解釈の精度が高まります。

**One-stepとTwo-stepのオプション**

RaRには、「One-step RaR」と「Two-step RaR」という2つのバリエーションがあります。One-step RaRは、単一のプロンプトを使用して言い換えた質問と回答を同時に生成します。一方、Two-step RaRは最初に質問を言い換え、その後で元の質問と言い換えた質問を組み合わせて応答します。のちほど詳細を紹介します。

![](https://ai-data-base.com/wp-content/uploads/2023/11/AIDB_51160_3-1024x263.png)

One-step RaRの例

![](https://ai-data-base.com/wp-content/uploads/2023/11/AIDB_51160_4-1024x268.png)

Two-step RaRの例

**教師なしでトレーニング不要**

RaRは教師なしでトレーニングが不要な手法であり、すべての質問に適用可能です。経済的であり、幅広い用途に利用できます。

**本記事の関連研究：**[GPT-4などLLMのコード生成能力にデバッグ機能を追加する『SELF-DEBUGGING（セルフデバッギング）』と実行プロンプト](https://ai-data-base.com/archives/57709)

## 実行プロンプト

### RaRのプロンプト形式

RaR（Rephrase and Respond）メソッドは、LLMが与えられた質問を再構築し、単一のプロンプトで応答するよう促します。例えば、特定の質問や指示に対して次のようなプロンプトを追加します。

プレミアム会員限定コンテンツです

閲覧には、アカウント作成後の決済が必要です。

*   全記事・論文コンテンツを無制限で閲覧可能
*   平日毎日更新、専門家による最新リサーチを配信

[プレミアム会員について](https://ai-data-base.com/premium-visitor)

Copyright © Parks, Inc. All rights reserved.
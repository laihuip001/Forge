---
source_url: https://ai-data-base.com/archives/65090
captured_at: 2026-01-18T13:23:51.425Z
title: "「人間の自然言語を超えて」LLMにタスク実行時の思考を非自然言語フォーマットで行わせるプロンプト手法『AutoForm（オートフォーム）』 - AIDB"
category: "unknown"
is_premium: false
publish_date: 2025-03-08T21:08:36+09:00
conversion_method: Readability+Turndown
file_hash: 43d4744556c08a9e
---

自然言語は人間の思考やコミュニケーションの基本フォーマットであり、大規模言語モデル（LLM）においても使われています。しかし、LLMは訓練時に、非自然言語（コードや論理式など）にも触れています。そこで出てくる疑問が、LLMの推論やエージェント間コミュニケーションに自然言語が最適なのだろうか？というものです。

そこで研究者らはLLMに最適な非自然言語フォーマットを自ら選択させることで、推論効率を向上させ、マルチエージェントコミュニケーションでのトークン使用量が最大72.7%削減できる手法を実証しました。※コミュニケーションの有効性は維持したまま

LLMはタスクの指示から独自のフォーマットを考案でき、考案したフォーマットが他のLLMにも転用できることがわかりました。

![](https://ai-data-base.com/wp-content/uploads/2024/03/AIDB_65090-1024x576.jpg)

**参照論文情報**

*   タイトル：Beyond Natural Language: LLMs Leveraging Alternative Formats for Enhanced Reasoning and Communication
*   機関：清華大学、テンセント、北京郵電大学
*   著者：Weize Chen, Chenfei Yuan, Jiarui Yuan, Yusheng Su, Chen Qian, Cheng Yang, Ruobing Xie, Zhiyuan Liu, Maosong Sun

**本記事の関連研究**：

*   [LLMにタスクに応じた推論プロセスを自ら考えるようにするプロンプト手法『SELF-DISCOVER』Google DeepMindなどが開発](https://ai-data-base.com/archives/64136)
*   [LLMに無礼なプロンプトを使用すると性能が低下し、間違えるリスクが増加する可能性](https://ai-data-base.com/archives/64959)
*   [GPT-4やGemini Pro1.0などさまざまなLLMで、プロンプトの入力が長くなるにつれて推論性能に顕著な低下が見られる](https://ai-data-base.com/archives/64873)
*   [GPT-4などに対してプロンプトのみから「新しい言葉の概念」を学習させるためのフレームワーク『FOCUS』](https://ai-data-base.com/archives/64594)
*   [LLMの思考の流れに沿ってプロンプトを与えるか否かで30%以上精度が変化する　DeepMindが報告](https://ai-data-base.com/archives/64551)

## 背景

自然言語は人間の考えや感情を表す基本的なツールと言えます。思考プロセスや情報交換に欠かせません。しかし、言語学者たちは「メンタレーゼ」（思考用言語）という概念を提唱しており、人間の思考は自然言語の枠を超えていると考えられています。

一方LLMの分野では、単一LLMの推論にしろ（Chain-of-Thoughtなど）、エージェント間のコミュニケーションにしろ、依然として自然言語に大きく依存しています。

人間の思考が自然言語を超えることを踏まえると、「LLMの推論やコミュニケーションに本当に自然言語が最適なのか」、「そうでない場合に、どう最適なフォーマットを決めればよいのか」という疑問が浮かんできます。

最近、LLMの推論やエージェント間コミュニケーションに自然言語以外のフォーマットの活用が模索されています。例えば、コードや数式（Program-of-Thought、X-of-Thoughtなど）を使うことでLLMの推論能力を高める試みです。しかし、こうした手法では外部ツールに依存することが多く、本当にフォーマット自体の効果があるのか、それともツール利用の効果なのかがわかりにくくなっています。  
さらに、自然言語には曖昧さや感情表現といった人間らしい特徴がありますが、エージェント間のやりとりには簡潔で正確なコミュニケーションが求められるため、必ずしも向いていないと考えられます。既存の研究では、エージェント間コミュニケーションでも自然言語の使用が主流であり、他のフォーマットの可能性についてはあまり検討されていません。

そこで研究者らは、単一LLMの推論やエージェント間コミュニケーションに自然言語以外のフォーマットを使うよう促す仕組みを開発して有効性を検証しました。

以下で詳しく紹介します。

プレミアム会員限定コンテンツです

閲覧には、アカウント作成後の決済が必要です。

*   全記事・論文コンテンツを無制限で閲覧可能
*   平日毎日更新、専門家による最新リサーチを配信

[プレミアム会員について](https://ai-data-base.com/premium-visitor)

Copyright © Parks, Inc. All rights reserved.
---
source_url: https://ai-data-base.com/archives/75649
captured_at: 2026-01-18T18:46:51.486397
title: "Self-Reflection（自己反省）がLLMのパフォーマンスに与える影響を網羅的に調査"
publish_date: 2024.09.13
tags: ["手法", "LLM", "エージェント", "コーディング", "手法\n426", "実証\n137", "分析\n54", "サーベイ\n37", "ベンチマーク・リソース\n22", "テクニカルレポート\n15", "ポジション\n8", "LLM\n659", "プロンプト技術\n156", "エージェント\n128", "コーディング\n56", "RAG\n50", "安全性\n39", "ペルソナ・シミュレーション\n36", "オープンソース\n25", "マルチモーダル\n23", "画像認識\n20", "セキュリティ\n16", "ハルシネーション\n16", "ファインチューニング\n16", "画像生成\n9", "音声\n8", "医療・ヘルスケア\n33", "政治・社会\n29", "エンタメ・アート\n23", "金融・経済\n10", "SE\n9", "教育・キャリア\n9", "製造・デザイン\n9", "ロボット\n6"]
conversion_method: browser_subagent_v1
is_premium: unknown
---

この記事では、LLMが自分自身の行動を反省して振り返る機能を持つことでどのような効果があるかについての研究を紹介します。

研究者たちは9種類のLLMと8種類の自己反省手法を使い、さまざまな分野の1,000問のテストで「問題を解く能力」がどれだけ良くなるかを調べました。

単に問題をもう一度解いてみるような簡単な方法から、詳しく説明を加えるような複雑な方法まで、さまざまなタイプの自己反省の効果を分析し、どの方法が一番効果的かを見つけ出そうとしました。

![](https://ai-data-base.com/wp-content/uploads/2024/09/AIDB_75649-1024x576.png)

## 背景

LLMベースのエージェント（LLMエージェント）の開発が進んでいます。LLMエージェントは複数の手順が必要な問題を解くこと、ウェブブラウザや検索エンジン、プログラムを実行するツールなども使えることが期待されています。

しかし、LLMエージェントには課題もあります。知識に限りがあったり、推論を間違えたり、実際にはない情報を出力したり、あまり意味のない繰り返しをしたりすることがあります。このような問題を改善するために、さまざまな能力が追加されたエージェントが設計されてきました。例えば、「考えの流れを示す方法」や「外部の記憶を使う方法」、「フィードバックから学ぶ方法」などが考案されてきました。

「自己反省」は、LLMエージェントが自分の思考を管理する戦略の一つとして注目されています。一部の研究では、LLMは自己反省を行うことで自らの間違いを見つけて直せることが分かっています。より詳しくは「LLMは推論の間違いを見つけることはできないが、外からのフィードバックを基に直せる可能性もある」と指摘されています。つまり、おそらく考えの間違いは正せないが、答えは修正できるということです。

そこで今回研究者らは、これまでの研究を踏まえて、LLMエージェントの問題解決性能を上げるために「自己反省」がどのように役立つかを調べることにしました。

## 研究手法

### データセット

この研究では、ARC、AGIEval、HellaSwag、MedMCQAなどの有名なLLMベンチマークから多肢選択式の問題が抽出されました。
データは標準フォーマットに変換され、10個のデータセットから各100問がランダムに選ばれ、合計1,000問からなる多分野試験が作成されました。

### モデル

今回の実験では、GPT-4、Llama 2 70B、Google Geminiなど、9種類の人気の高いLLMが評価されました。

### エージェント

研究では、8種類の自己反省型LLMエージェントが調査されました。

（１）再試行タイプ：単純に再挑戦する
（２）キーワードタイプ：エラーに関するキーワードを受け取る
（３）アドバイスタイプ：一般的なアドバイスを受け取る
（４）説明タイプ：エラーの理由の説明を受け取る
（５）指示タイプ：順序付きの指示を受け取る
（６）解答タイプ：段階的な解答を受け取る
（７）複合タイプ：上記全てを含む
（８）未編集タイプ：正解込みの情報を含む（理論的上限）

## 結果

### エージェント別パフォーマンス

分析の結果、全てのLLMにおいて、全ての自己反省タイプで統計的に有意なパフォーマンスの向上が見られました（p < 0.001）。
GPT-4の場合、ベースラインの79%に対し、「再試行」で83%、「解答」や「複合」では93%まで向上しました。

### モデル別パフォーマンス

テストされた全てのLLM（Claude 3 Opus, Llama 2 7b等）において、自己反省による改善パターンが類似していることが分かりました。

### テスト別パフォーマンス

LSAT-AR（分析的推論）試験で最も大きな改善が見られた一方、SAT英語試験などでは効果が比較的小さいものでした。複雑な推論を要する問題において、自己反省の効果が顕著に表れる傾向があります。

## 考察

「再試行」だけでも効果があるのは、2回目の試行でより慎重になるか、あるいは2番目に可能性の高い答えを選択している可能性が考えられます。

実用的な観点からは、自身の間違いを自己反省できるエージェントは、将来的に同様の間違いを避けることを学習でき、エージェントが同じ間違いを繰り返す「非生産的ループ」の防止に役立ちます。

## まとめ

研究の結果、どのような方法で自分を振り返っても、問題を解く能力が良くなることが分かりました。中でも、詳しい説明や問題の解き方を含む自己反省が最も効果的で、LLMの種類や問題の分野によらず有効でした。

参照論文情報
- タイトル：Self-Reflection in LLM Agents: Effects on Problem-Solving Performance
- 著者：Matthew Renze, Erhan Guven
- 参照論文URL：https://arxiv.org/abs/2405.06682